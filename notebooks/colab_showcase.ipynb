{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AstroGraphAnomaly \u2014 Colab Showcase (analyse + graphiques)\n\nObjectif : d\u00e9montrer au maximum les capacit\u00e9s du workflow :\n- ex\u00e9cution offline (CSV test) + multi-engines\n- comparaison de stabilit\u00e9 (overlap top anomalies)\n- analyses stats (quantiles, entropie) + PCA\n- analyses graphe (communaut\u00e9s, k-core, betweenness, articulation, bridges)\n- visualisations (score hist, RA/Dec, CMD si bp_rp, graphe color\u00e9)\n- explainability (LIME) + lecture prompts LLM\n\nCe notebook d\u00e9tecte automatiquement l\u2019entrypoint : `workflow.py` ou `run_workflow.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "!git clone --depth 1 https://github.com/dalozedidier-dot/AstroGraphAnomaly.git\n",
        "%cd AstroGraphAnomaly\n",
        "!python -m pip install -q --upgrade pip\n",
        "!pip -q install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Helpers (d\u00e9tection entrypoint + runner)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, sys, subprocess, json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "ENTRYPOINT = None\n",
        "if Path('workflow.py').exists():\n",
        "    ENTRYPOINT = 'workflow.py'\n",
        "elif Path('run_workflow.py').exists():\n",
        "    ENTRYPOINT = 'run_workflow.py'\n",
        "else:\n",
        "    raise FileNotFoundError('Aucun entrypoint trouv\u00e9: workflow.py ou run_workflow.py')\n",
        "print('Entrypoint d\u00e9tect\u00e9:', ENTRYPOINT)\n",
        "\n",
        "def run_job(mode: str, out_dir: str, **kw):\n",
        "    out = Path(out_dir)\n",
        "    out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if ENTRYPOINT == 'workflow.py':\n",
        "        cmd = [sys.executable, ENTRYPOINT, mode]\n",
        "        if mode in ('csv','hubble'):\n",
        "            cmd += ['--in-csv', kw['in_csv']]\n",
        "        if mode == 'gaia':\n",
        "            cmd += ['--ra', str(kw['ra']), '--dec', str(kw['dec'])]\n",
        "            cmd += ['--radius-deg', str(kw.get('radius_deg', 0.3)), '--limit', str(kw.get('limit', 800))]\n",
        "        cmd += ['--out', str(out)]\n",
        "\n",
        "        # options\n",
        "        cmd += ['--engine', kw.get('engine','isolation_forest')]\n",
        "        cmd += ['--threshold-strategy', kw.get('threshold_strategy','top_k')]\n",
        "        cmd += ['--top-k', str(kw.get('top_k', 30))]\n",
        "        cmd += ['--explain-top', str(kw.get('explain_top', 10))]\n",
        "        cmd += ['--knn-k', str(kw.get('knn_k', 8))]\n",
        "        cmd += ['--features-mode', kw.get('features_mode', 'extended')]\n",
        "        if kw.get('plots', True):\n",
        "            cmd += ['--plots']\n",
        "    else:\n",
        "        cmd = [sys.executable, ENTRYPOINT, '--mode', mode]\n",
        "        if mode in ('csv','hubble'):\n",
        "            cmd += ['--in-csv', kw['in_csv']]\n",
        "        if mode == 'gaia':\n",
        "            cmd += ['--ra', str(kw['ra']), '--dec', str(kw['dec'])]\n",
        "            cmd += ['--radius-deg', str(kw.get('radius_deg', 0.3)), '--limit', str(kw.get('limit', 800))]\n",
        "        cmd += ['--out', str(out)]\n",
        "\n",
        "        cmd += ['--engine', kw.get('engine','isolation_forest')]\n",
        "        cmd += ['--threshold-strategy', kw.get('threshold_strategy','top_k')]\n",
        "        cmd += ['--top-k', str(kw.get('top_k', 30))]\n",
        "        cmd += ['--explain-top', str(kw.get('explain_top', 10))]\n",
        "        cmd += ['--knn-k', str(kw.get('knn_k', 8))]\n",
        "        cmd += ['--features-mode', kw.get('features_mode', 'extended')]\n",
        "        if kw.get('plots', True):\n",
        "            cmd += ['--plots']\n",
        "\n",
        "    print('RUN:', ' '.join(cmd))\n",
        "    subprocess.check_call(cmd)\n",
        "    return out\n",
        "\n",
        "def load_outputs(out: Path):\n",
        "    scored = pd.read_csv(out/'scored.csv')\n",
        "    top = pd.read_csv(out/'top_anomalies.csv')\n",
        "    return scored, top\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Run showcase offline (CSV test fourni)\nOn lance plusieurs engines pour comparer la stabilit\u00e9 des anomalies et produire le maximum d\u2019artefacts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "DATA_CSV = 'data/sample_gaia_like.csv'\n",
        "BASE_OUT = Path('results/showcase_offline')\n",
        "BASE_OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "ENGINES = ['isolation_forest', 'lof', 'ocsvm', 'robust_zscore']\n",
        "runs = {}\n",
        "for eng in ENGINES:\n",
        "    out = run_job(\n",
        "        mode='csv',\n",
        "        in_csv=DATA_CSV,\n",
        "        out_dir=str(BASE_OUT/eng),\n",
        "        engine=eng,\n",
        "        threshold_strategy='top_k',\n",
        "        top_k=30,\n",
        "        explain_top=10,\n",
        "        knn_k=8,\n",
        "        features_mode='extended',\n",
        "        plots=True,\n",
        "    )\n",
        "    runs[eng] = out\n",
        "print('Done. Runs:', {k:str(v) for k,v in runs.items()})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Sanity + synth\u00e8se rapide (n, anomalies, quantiles, entropie)\nEntropie calcul\u00e9e sur la distribution des labels (anomalie vs normal) et sur la distribution des scores (buckets)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def entropy_from_counts(counts):\n",
        "    total = sum(counts)\n",
        "    if total <= 0:\n",
        "        return 0.0\n",
        "    ent = 0.0\n",
        "    for c in counts:\n",
        "        if c <= 0:\n",
        "            continue\n",
        "        p = c/total\n",
        "        ent -= p * math.log(p + 1e-12)\n",
        "    return ent\n",
        "\n",
        "summary_rows = []\n",
        "for eng, out in runs.items():\n",
        "    scored, top = load_outputs(out)\n",
        "    n = len(scored)\n",
        "    n_anom = int((scored['anomaly_label'] == -1).sum()) if 'anomaly_label' in scored.columns else None\n",
        "\n",
        "    s = scored['anomaly_score'].to_numpy(float)\n",
        "    q = np.quantile(s, [0,0.1,0.5,0.9,1.0]).tolist()\n",
        "\n",
        "    # entropy of label distribution\n",
        "    if n_anom is not None:\n",
        "        ent_lbl = entropy_from_counts([n_anom, n-n_anom])\n",
        "    else:\n",
        "        ent_lbl = None\n",
        "    # entropy of score histogram\n",
        "    hist, _ = np.histogram(s, bins=20)\n",
        "    ent_score = entropy_from_counts(hist.tolist())\n",
        "\n",
        "    summary_rows.append({\n",
        "        'engine': eng,\n",
        "        'n': n,\n",
        "        'n_anomalies(label=-1)': n_anom,\n",
        "        'q0': q[0], 'q10': q[1], 'q50': q[2], 'q90': q[3], 'q100': q[4],\n",
        "        'entropy_labels': ent_lbl,\n",
        "        'entropy_score_hist': ent_score,\n",
        "    })\n",
        "\n",
        "summary = pd.DataFrame(summary_rows)\n",
        "summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Overlap des top anomalies (Jaccard)\nOn compare l\u2019ensemble des `source_id` du top-k entre engines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "tops = {}\n",
        "for eng, out in runs.items():\n",
        "    _, top = load_outputs(out)\n",
        "    tops[eng] = set(top['source_id'].astype('int64').tolist())\n",
        "\n",
        "eng_list = list(tops.keys())\n",
        "J = np.zeros((len(eng_list), len(eng_list)), dtype=float)\n",
        "for i,a in enumerate(eng_list):\n",
        "    for j,b in enumerate(eng_list):\n",
        "        inter = len(tops[a].intersection(tops[b]))\n",
        "        union = len(tops[a].union(tops[b]))\n",
        "        J[i,j] = inter/union if union else 0.0\n",
        "\n",
        "J_df = pd.DataFrame(J, index=eng_list, columns=eng_list)\n",
        "J_df\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.imshow(J, aspect='auto')\n",
        "plt.xticks(range(len(eng_list)), eng_list, rotation=45, ha='right')\n",
        "plt.yticks(range(len(eng_list)), eng_list)\n",
        "plt.title('Jaccard overlap of top anomalies (top_k=30)')\n",
        "plt.colorbar(label='Jaccard')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Visualisations comparatives des scores\n- histogrammes par engine\n- scatter RA/Dec color\u00e9 par score (engine choisi)\n- PCA 2D (features num\u00e9riques) avec anomalies surlign\u00e9es"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.figure(figsize=(9,6))\n",
        "for eng, out in runs.items():\n",
        "    scored, _ = load_outputs(out)\n",
        "    plt.hist(scored['anomaly_score'].to_numpy(float), bins=60, alpha=0.45, label=eng)\n",
        "plt.title('Score distributions (overlay)')\n",
        "plt.xlabel('anomaly_score'); plt.ylabel('count')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Choisir un engine pour les visualisations spatiales\n",
        "ENGINE_VIEW = 'isolation_forest'\n",
        "scored, top = load_outputs(runs[ENGINE_VIEW])\n",
        "\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.scatter(scored['ra'], scored['dec'], c=scored['anomaly_score'], s=18, alpha=0.85)\n",
        "plt.colorbar(label='anomaly_score')\n",
        "plt.title(f'RA/Dec colored by score ({ENGINE_VIEW})')\n",
        "plt.xlabel('ra'); plt.ylabel('dec')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Numeric feature block from scored.csv (auto)\n",
        "num_cols = [c for c in scored.columns if c not in ('source_id') and pd.api.types.is_numeric_dtype(scored[c])]\n",
        "X = scored[num_cols].replace([np.inf, -np.inf], np.nan).fillna(0.0).to_numpy(float)\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "Z = pca.fit_transform(X)\n",
        "\n",
        "is_anom = scored['anomaly_label'].to_numpy(int) == -1 if 'anomaly_label' in scored.columns else np.zeros(len(scored), dtype=bool)\n",
        "\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.scatter(Z[~is_anom,0], Z[~is_anom,1], s=10, alpha=0.5)\n",
        "plt.scatter(Z[is_anom,0], Z[is_anom,1], s=22, alpha=0.9)\n",
        "plt.title(f'PCA(2) on scored numeric columns ({ENGINE_VIEW})')\n",
        "plt.xlabel('PC1'); plt.ylabel('PC2')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('Explained variance ratio:', pca.explained_variance_ratio_.tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Analyse graphe (GraphML)\nOn recharge `graph_full.graphml` et on calcule des m\u00e9triques : degree, clustering, k-core, betweenness (approx), communaut\u00e9s, articulation, bridges.\nPuis on visualise :\n- distribution degree/kcore/betweenness\n- tailles de communaut\u00e9s\n- graphe top-k color\u00e9 par communaut\u00e9 et anomalies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "\n",
        "G_full = nx.read_graphml(runs[ENGINE_VIEW]/'graph_full.graphml')\n",
        "G_top = nx.read_graphml(runs[ENGINE_VIEW]/'graph_topk.graphml')\n",
        "print('G_full:', G_full.number_of_nodes(), 'nodes', G_full.number_of_edges(), 'edges')\n",
        "print('G_top :', G_top.number_of_nodes(), 'nodes', G_top.number_of_edges(), 'edges')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Convert node ids to a stable list (GraphML often loads as str)\n",
        "nodes = list(G_full.nodes())\n",
        "deg = dict(G_full.degree())\n",
        "clust = nx.clustering(G_full)\n",
        "core = nx.core_number(G_full) if G_full.number_of_nodes() > 0 else {n:0 for n in nodes}\n",
        "\n",
        "# betweenness approx (k limited)\n",
        "k = min(300, len(nodes))\n",
        "btw = nx.betweenness_centrality(G_full, k=k, normalized=True, seed=42) if len(nodes) > 1 else {n:0.0 for n in nodes}\n",
        "\n",
        "# communities (Louvain if available)\n",
        "try:\n",
        "    from networkx.algorithms.community import louvain_communities\n",
        "    comms = louvain_communities(G_full, seed=42)\n",
        "except Exception:\n",
        "    from networkx.algorithms.community import greedy_modularity_communities\n",
        "    comms = greedy_modularity_communities(G_full)\n",
        "\n",
        "comm_id = {}\n",
        "for i, cset in enumerate(comms):\n",
        "    for n in cset:\n",
        "        comm_id[n] = i\n",
        "\n",
        "aps = set(nx.articulation_points(G_full)) if G_full.number_of_nodes() > 2 else set()\n",
        "try:\n",
        "    bridges = list(nx.bridges(G_full))\n",
        "    bridge_nodes = set([a for a,b in bridges] + [b for a,b in bridges])\n",
        "except Exception:\n",
        "    bridge_nodes = set()\n",
        "\n",
        "gdf = pd.DataFrame({\n",
        "    'node': nodes,\n",
        "    'degree': [deg.get(n,0) for n in nodes],\n",
        "    'clustering': [clust.get(n,0.0) for n in nodes],\n",
        "    'kcore': [core.get(n,0) for n in nodes],\n",
        "    'betweenness': [btw.get(n,0.0) for n in nodes],\n",
        "    'community': [comm_id.get(n,-1) for n in nodes],\n",
        "    'is_articulation': [1 if n in aps else 0 for n in nodes],\n",
        "    'incident_to_bridge': [1 if n in bridge_nodes else 0 for n in nodes],\n",
        "})\n",
        "gdf.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.figure(figsize=(9,6))\n",
        "plt.hist(gdf['degree'], bins=50, alpha=0.8)\n",
        "plt.title('Degree distribution')\n",
        "plt.xlabel('degree'); plt.ylabel('count')\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.hist(gdf['kcore'], bins=30, alpha=0.8)\n",
        "plt.title('k-core distribution')\n",
        "plt.xlabel('kcore'); plt.ylabel('count')\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.hist(gdf['betweenness'], bins=60, alpha=0.8)\n",
        "plt.title('Betweenness distribution (approx)')\n",
        "plt.xlabel('betweenness'); plt.ylabel('count')\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Community sizes\n",
        "cs = gdf.groupby('community').size().sort_values(ascending=False)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.bar(range(len(cs.head(25))), cs.head(25).to_numpy())\n",
        "plt.title('Top community sizes (up to 25)')\n",
        "plt.xlabel('community rank'); plt.ylabel('size')\n",
        "plt.tight_layout(); plt.show()\n",
        "cs.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Plot top-k graph colored by community, anomalies highlighted\n",
        "top_ids = set(top['source_id'].astype(str).tolist())\n",
        "anom_ids = set(scored.loc[scored['anomaly_label']==-1,'source_id'].astype(str).tolist()) if 'anomaly_label' in scored.columns else set()\n",
        "\n",
        "pos = nx.spring_layout(G_top, seed=42)\n",
        "\n",
        "node_list = list(G_top.nodes())\n",
        "node_colors = []\n",
        "sizes = []\n",
        "for n in node_list:\n",
        "    c = comm_id.get(n, 0)\n",
        "    node_colors.append(c)\n",
        "    sizes.append(55 if n in anom_ids else 20)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "nx.draw(G_top, pos, node_size=sizes, node_color=node_colors, with_labels=False, alpha=0.85, width=0.4)\n",
        "plt.title('Top-k subgraph colored by community (larger = anomaly)')\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Explainability (LIME) + prompts LLM\nOn lit `explanations.jsonl` et `llm_prompts.jsonl` (si pr\u00e9sents), puis on visualise les poids LIME du premier \u00e9l\u00e9ment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "exp_path = runs[ENGINE_VIEW] / 'explanations.jsonl'\n",
        "prm_path = runs[ENGINE_VIEW] / 'llm_prompts.jsonl'\n",
        "print('explanations exists:', exp_path.exists())\n",
        "print('prompts exists:', prm_path.exists())\n",
        "\n",
        "first_exp = None\n",
        "if exp_path.exists():\n",
        "    with exp_path.open('r', encoding='utf-8') as f:\n",
        "        first_exp = json.loads(next(f))\n",
        "    first_exp.keys(), first_exp.get('source_id')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if first_exp is not None:\n",
        "    weights = first_exp.get('lime', {}).get('weights', [])\n",
        "    if weights:\n",
        "        # take top 12 by abs(weight)\n",
        "        weights = sorted(weights, key=lambda w: abs(w.get('weight',0.0)), reverse=True)[:12]\n",
        "        labels = [w['feature'] for w in weights]\n",
        "        vals = [w['weight'] for w in weights]\n",
        "        plt.figure(figsize=(10,5))\n",
        "        plt.bar(range(len(vals)), vals)\n",
        "        plt.xticks(range(len(vals)), labels, rotation=45, ha='right')\n",
        "        plt.title('LIME weights (first explained anomaly)')\n",
        "        plt.tight_layout(); plt.show()\n",
        "    else:\n",
        "        print('No LIME weights (lime missing or fallback).')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if prm_path.exists():\n",
        "    with prm_path.open('r', encoding='utf-8') as f:\n",
        "        obj = json.loads(next(f))\n",
        "    print('Prompt sample for source_id:', obj.get('source_id'))\n",
        "    print(obj.get('prompt')[:1600])\n",
        "else:\n",
        "    print('No prompts file found.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Optionnel : Gaia run (r\u00e9seau requis)\nD\u00e9commenter pour ex\u00e9cuter Gaia et obtenir `bp_rp` + CMD (si activ\u00e9 dans la requ\u00eate)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# out_gaia = run_job(\n",
        "#     mode='gaia',\n",
        "#     ra=266.4051, dec=-28.936175,\n",
        "#     radius_deg=0.3,\n",
        "#     limit=800,\n",
        "#     out_dir='results/showcase_gaia/isolation_forest',\n",
        "#     engine='isolation_forest',\n",
        "#     threshold_strategy='top_k',\n",
        "#     top_k=30,\n",
        "#     explain_top=10,\n",
        "#     knn_k=8,\n",
        "#     features_mode='extended',\n",
        "#     plots=True,\n",
        "# )\n",
        "# print('Gaia outputs in:', out_gaia)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "colab_showcase.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}